{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b34572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 导入需要的库\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import albumentations as AL   # pip install albumentations==1.1.0  \n",
    "from albumentations.pytorch import ToTensorV2  \n",
    "import torchvision  \n",
    "from torchvision import datasets,transforms  \n",
    "from tqdm import tqdm  \n",
    "import cv2  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim  \n",
    "from PIL import Image  \n",
    "import os  \n",
    "import torch.nn.functional as F  \n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cf7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 定义参数  \n",
    "LR = 1e-4  \n",
    "SPLIT = 0.2  \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "BATCH_SIZE = 4  \n",
    "EPOCHS = 2  \n",
    "DATAPATH = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34951296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3  读取数据\n",
    "\n",
    "# 读取 train.csv文件  \n",
    "df = pd.read_csv(DATAPATH + '/train.csv')  \n",
    "df.bbox = df.bbox.apply(ast.literal_eval)   #  字符串列表转列表 \n",
    "  \n",
    "# 利用groupby 将同一个image_id的数据进行聚合，在同一list，并且用reset_index直接转变成dataframe  \n",
    "df = df.groupby(\"image_id\")[\"bbox\"].apply(list).reset_index(name=\"bboxes\") \n",
    "\n",
    "\n",
    "# 4  划分数据\n",
    "def train_test_split(dataFrame,split):  \n",
    "    len_tot = len(dataFrame)  \n",
    "    val_len = int(split*len_tot)  \n",
    "    train_len = len_tot-val_len  \n",
    "    train_data,val_data = dataFrame.iloc[:train_len][:],dataFrame.iloc[train_len:][:]  \n",
    "    return train_data,val_data  \n",
    "\n",
    "\n",
    "# print(len(df))    \n",
    "train_data_df,val_data_df = train_test_split(df,SPLIT)  # 划分 train val 8:2  \n",
    "# print(len(train_data_df), len(val_data_df))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 定义WheatDataset 返回 图片，标签  \n",
    "class WheatDataset(Dataset):  \n",
    "    def __init__(self,data,root_dir,transform=None,train=True):  \n",
    "        self.data = data  \n",
    "        self.root_dir = root_dir  \n",
    "        self.image_names = self.data.image_id.values  \n",
    "        self.bboxes = self.data.bboxes.values  \n",
    "        self.transform = transform  \n",
    "        self.isTrain = train  \n",
    "    def __len__(self):  \n",
    "        return len(self.data)  \n",
    "    def __getitem__(self,index):  \n",
    "#         print(self.image_names)  \n",
    "#         print(self.bboxes)  \n",
    "        img_path = os.path.join(self.root_dir,self.image_names[index]+\".jpg\")  # 拼接路径  \n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)   # 读取图片  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)  # BGR2RGB  \n",
    "        image /= 255.0    # 归一化  \n",
    "        bboxes = torch.tensor(self.bboxes[index],dtype=torch.float64)  \n",
    "#         print(bboxes)  \n",
    "        \n",
    "        bboxes[:,2] = bboxes[:,0]+bboxes[:,2]   # 格式转换 (xmin,ymin,width,height)-----> (xmin,ymin,xmax,ymax)  \n",
    "        bboxes[:,3] = bboxes[:,1]+bboxes[:,3]  \n",
    "#         print(image.size,type(image))  \n",
    "        \"\"\"  \n",
    "            we need to return image and a target dictionary  \n",
    "            target:  \n",
    "                boxes,labels,image_id,area,iscrowd  \n",
    "        \"\"\"  \n",
    "        area = (bboxes[:,3]-bboxes[:,1])*(bboxes[:,2]-bboxes[:,0])   # 计算面积  \n",
    "        area = torch.as_tensor(area,dtype=torch.float32)  \n",
    "          \n",
    "        # there is only one class  \n",
    "        labels = torch.ones((len(bboxes),),dtype=torch.int64)   # 标签  \n",
    "          \n",
    "        # suppose all instances are not crowded  \n",
    "        iscrowd = torch.zeros((len(bboxes),),dtype=torch.int64)  \n",
    "          \n",
    "        target = {}   # target是个字典 里面 包括 boxes,labels,image_id,area,iscrowd  \n",
    "        target['boxes'] = bboxes  \n",
    "        target['labels']= labels  \n",
    "        target['image_id'] = torch.tensor([index])  \n",
    "        target[\"area\"] = area  \n",
    "        target['iscrowd'] = iscrowd  \n",
    "          \n",
    "        if self.transform is not None:  \n",
    "            sample = {  \n",
    "                'image': image,  \n",
    "                'bboxes': target['boxes'],  \n",
    "                'labels': labels  \n",
    "            }  \n",
    "            sample = self.transform(**sample)  \n",
    "            image = sample['image']  \n",
    "              \n",
    "            # 沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状，   \n",
    "#             把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在增加新的维度进行堆叠  \n",
    "            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)  \n",
    "              \n",
    "        return image,target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae13508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 数据增强  利用albumentations  随机翻转转换，随机图片处理  张量转换  读取格式\n",
    "# 对象检测的增强与正常增强不同，因为在这里需要确保 bbox 在转换后仍然正确与对象对齐  \n",
    "train_transform = AL.Compose([  AL.Flip(0.5),  ToTensorV2(p=1.0)  ],bbox_params = {'format':\"pascal_voc\",'label_fields': ['labels']})  \n",
    "val_transform = AL.Compose([  ToTensorV2(p=1.0)  ],bbox_params = {'format':\"pascal_voc\",\"label_fields\":['labels']})  \n",
    "\n",
    "#7 数据整理\n",
    " \n",
    "\"\"\"  \n",
    "collate_fn默认是对数据图片通过torch.stack()进行简单的拼接。对于分类网络来说，默认方法是可以的（因为传入的就是数据的图片），  \n",
    "但是对于目标检测来说train_dataset返回的是一个tuple,即(image, target)。  \n",
    "如果我们还是采用默认的合并方法，那么就会出错。  \n",
    "所以我们需要自定义一个方法即collate_fn=train_dataset.collate_fn  \n",
    "\"\"\"  \n",
    "def collate_fn(batch):  \n",
    "    return tuple(zip(*batch))  \n",
    "\n",
    "#8 创建数据\n",
    "\n",
    "train_data = WheatDataset(train_data_df,DATAPATH+\"/train\",transform=train_transform)  \n",
    "valid_data = WheatDataset(val_data_df,DATAPATH+\"/train\",transform=val_transform)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053372b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 查看一个训练集中的数据  \n",
    "image,target = train_data.__getitem__(0)  \n",
    "plt.imshow(image.numpy().transpose(1,2,0))  \n",
    "print(image.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2645d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 定义模型\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor  \n",
    "  \n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)  \n",
    "num_classes = 2  \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features  \n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 定义Averager类  保存对应的loss  \n",
    "class Averager:  \n",
    "    def __init__(self):  \n",
    "        self.current_total = 0.0  \n",
    "        self.iterations = 0.0  \n",
    "  \n",
    "    def send(self, value):  \n",
    "        self.current_total += value  \n",
    "        self.iterations += 1  \n",
    "  \n",
    "    @property  \n",
    "    def value(self):  \n",
    "        if self.iterations == 0:  \n",
    "            return 0  \n",
    "        else:  \n",
    "            return 1.0 * self.current_total / self.iterations  \n",
    "  \n",
    "    def reset(self):  \n",
    "        self.current_total = 0.0  \n",
    "        self.iterations = 0.0  \n",
    "\n",
    "#12 构建训练和测试 dataloader\n",
    " \n",
    "train_dataloader = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_fn)  \n",
    "val_dataloader = DataLoader(valid_data,batch_size=BATCH_SIZE,shuffle=False,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dadca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 定义模型参数 优化器，损失， 迭代，以及 学习率  \n",
    "train_loss = []  \n",
    "# val_loss = []  \n",
    "model = model.to(DEVICE)  \n",
    "params =[p for p in model.parameters() if p.requires_grad]  \n",
    "optimizer = optim.Adam(params,lr=LR)  \n",
    "loss_hist = Averager()  \n",
    "itr = 1  \n",
    "lr_scheduler=None  \n",
    "  \n",
    "\n",
    "#14 模型训练\n",
    "if __name__ == '__main__':  \n",
    "  \n",
    "    for epoch in range(EPOCHS):  \n",
    "        loss_hist.reset()  \n",
    "  \n",
    "        for images, targets in train_dataloader:  \n",
    "  \n",
    "            # print(images)  \n",
    "            # print(targets)  \n",
    "  \n",
    "            # for image in images:  \n",
    "            #     print(image.dtype)  # torch.float32  \n",
    "  \n",
    "            # for t in targets:  \n",
    "            #     for k, v in t.items():  \n",
    "            #         print(k ,v.dtype)  \n",
    "  \n",
    "            images = list(image.to(DEVICE) for image in images)  \n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]  \n",
    "  \n",
    "  \n",
    "            loss_dict = model(images, targets)  \n",
    "  \n",
    "            # for loss in loss_dict.values():  \n",
    "            #     print(loss.dtype)  \n",
    "  \n",
    "            losses = sum(loss for loss in loss_dict.values())  \n",
    "            loss_value = losses.item()  \n",
    "  \n",
    "            loss_hist.send(loss_value)  \n",
    "  \n",
    "            optimizer.zero_grad()  \n",
    "            losses.backward()  \n",
    "            optimizer.step()  \n",
    "  \n",
    "            if itr % 50 == 0:  \n",
    "                print(f\"Iteration #{itr} loss: {loss_value}\")  \n",
    "  \n",
    "            itr += 1  \n",
    "  \n",
    "        # update the learning rate  \n",
    "        if lr_scheduler is not None:  \n",
    "            lr_scheduler.step()  \n",
    "  \n",
    "        print(f\"Epoch #{epoch} loss: {loss_hist.value}\")  \n",
    "\n",
    "\n",
    "# 15  模型保存  \n",
    "torch.save(model.state_dict(), 'fasterrcnn_resnet50_fpn.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae4459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
